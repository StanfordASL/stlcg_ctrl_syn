{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../../stlcg_karen/src')\n",
    "sys.path.append('../../stlcg_karen/src')\n",
    "import stlcg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "\n",
    "from torch_interpolations.torch_interpolations.multilinear import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = sio.loadmat('../hji/data/value.mat');\n",
    "deriv_value = sio.loadmat('../hji/data/deriv_value.mat');\n",
    "V = value['data'];\n",
    "dV = [deriv_value['derivC'][i][0] for i in range(4)];\n",
    "g = sio.loadmat('../hji/data/grid.mat')['grid'];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values = torch.tensor(V[:,:,:,:,-1]).float()\n",
    "points = [torch.from_numpy(g[i][0].flatten()).float() for i in range(4)]\n",
    "value_interp = RegularGridInterpolator(points, values)\n",
    "deriv_interp = [RegularGridInterpolator(points, torch.tensor(dV[i][:,:,:,:,-1]).float()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-5.0000, -4.5000, -4.0000]),\n",
       " tensor([0.0000, 0.3000, 0.6000]),\n",
       " tensor([-3.1416, -2.9883, -2.8351]),\n",
       " tensor([0.0000, 0.2500, 0.5000])]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p[:3] for p in points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HJIValueFunction(torch.autograd.Function):\n",
    "        \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        [bs, x_dim]\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return value_interp(input.split(1, dim=1))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        points = input.split(1, dim=1)\n",
    "        gr = torch.zeros_like(input)\n",
    "        return  torch.cat([deriv_interp[i](points) for i in range(4)], 1) * grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = HJIValueFunction.apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0000,  0.0000, -3.1416,  0.0000],\n",
       "        [-4.5000,  0.3000, -2.9883,  0.2500],\n",
       "        [-4.0000,  0.6000, -2.8351,  0.5000]], requires_grad=True)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.stack([p[:3] for p in points], 1).float().requires_grad_(True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = vf(inputs[1:2,:]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4053, -0.5063,  9.4112, -1.3243],\n",
       "        [-0.2907, -0.4539,  2.7025, -0.4282],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4053, -0.5063,  9.4112, -1.3243],\n",
       "        [-0.2907, -0.4539,  2.7025, -0.4282],\n",
       "        [-0.1980, -0.4046, -0.4952, -0.0190]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([deriv_interp[i]([p[:3] for p in points]) for i in range(4)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0000,  0.0000, -3.1416,  0.0000],\n",
       "        [-4.5000,  0.3000, -2.9883,  0.2500],\n",
       "        [-4.0000,  0.6000, -2.8351,  0.5000]], requires_grad=True)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../hji/data/expert_traj.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertDemoDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, npy_file):\n",
    "        \n",
    "        # [t, x, y, psi, V]\n",
    "        self.data = np.load(npy_file)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        time = self.data[idx, 0]\n",
    "        state = self.data[idx, 1:5]\n",
    "        control = self.data[idx, 5:7]\n",
    "        return {'state': state, 'control': control, 'time': time}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 8\n",
    "num_layers = 1\n",
    "ctrl_dim = 2\n",
    "lstm = torch.nn.LSTM(input_size, hidden_size, num_layers)\n",
    "proj = torch.nn.Linear(hidden_size, ctrl_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(data[:,1:5]).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "o, (h,c) = lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj(h).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "?lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamics(x_prev, u):\n",
    "    return 2 * x_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "x_partial = inputs[:10, :,:]\n",
    "o, (h, c) = lstm(x_partial)    # h is the last hidden state/last output\n",
    "u = proj(h)    # [1, bs, ctrl_dim]\n",
    "x_future = []\n",
    "x_prev = x_partial[-1:, :,:]\n",
    "\n",
    "for i in range(n):\n",
    "    x_next = dynamics(x_prev, u)\n",
    "    x_future.append(x_next)\n",
    "    u = lstm(x_next, (h,c))\n",
    "    x_prev = x_next\n",
    "return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8fd6fba58037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../hji/data/value.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mderiv_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../hji/data/deriv_value.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mderiv_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derivC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sio' is not defined"
     ]
    }
   ],
   "source": [
    "value = sio.loadmat('../hji/data/value.mat');\n",
    "deriv_value = sio.loadmat('../hji/data/deriv_value.mat');\n",
    "V = value['data'];\n",
    "dV = [deriv_value['derivC'][i][0] for i in range(4)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_tensor = torch.tensor(V[:3,:3,0,0,-1]).float()\n",
    "V_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torch.arange(3, dtype=torch.float32).view(1, 1, 3, 1)\n",
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [1., 1., 1.],\n",
       "          [2., 2., 2.]]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.repeat([1,1,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.0005, 4.8486, 4.6865],\n",
       "          [4.7978, 4.6409, 4.4837],\n",
       "          [4.6112, 4.4454, 4.2903]]]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_tensor.unsqueeze(0).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.0005, 4.9397, 4.8790, 4.8162, 4.7513, 4.6865],\n",
       "          [4.9194, 4.8579, 4.7963, 4.7335, 4.6694, 4.6054],\n",
       "          [4.8384, 4.7760, 4.7136, 4.6508, 4.5875, 4.5243],\n",
       "          [4.7605, 4.6970, 4.6335, 4.5705, 4.5077, 4.4450],\n",
       "          [4.6858, 4.6209, 4.5561, 4.4924, 4.4300, 4.3676],\n",
       "          [4.6112, 4.5449, 4.4786, 4.4144, 4.3523, 4.2903]]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(V_tensor.unsqueeze(0).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.000489, 4.848586, 4.686505], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_tensor[0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STLPolicy(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, state_dim, ctrl_dim, hidden_dim, num_layers=1):\n",
    "        super(STLPolicy, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(state_dim, hidden_dim, num_layers)\n",
    "        self.proj = torch.nn.Linear(hidden_dim, ctrl_dim)\n",
    "        self.L2loss = torch.nn.MSELoss()\n",
    "\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        # x is [time_dim, bs, state_dim]\n",
    "        o, _ = self.lstm(x)    # [time_dim, bs, hidden_dim] , bs = 1 for a single expert trajectory.\n",
    "        u = self.proj(o)    # [time_dim, bs, ctrl_dim]\n",
    "        return o, u\n",
    "            \n",
    "    \n",
    "    def propagate_n(self, n, x_partial, dynamics):\n",
    "        '''\n",
    "        n is the number of time steps to propagate forward\n",
    "        x_partial is the input trajectory [time_dim, bs, state_dim]\n",
    "        dynamics is a function that takes in x and u and gives the next state\n",
    "        '''\n",
    "        o, (h, c) = self.lstm(x_partial)    # h is the last hidden state/last output\n",
    "        u = self.proj(h)    # [1, bs, ctrl_dim]\n",
    "        x_future = []\n",
    "        x_prev = x_partial[-1:, :,:]\n",
    "\n",
    "        for i in range(n):\n",
    "            x_next = dynamics(x_prev, u)\n",
    "            x_future.append(x_next)\n",
    "            u = self.lstm(x_next, (h,c))\n",
    "            x_prev = x_next\n",
    "                \n",
    "        return torch.cat(x_future, 0)\n",
    "        \n",
    "        \n",
    "    def control_loss(self, x_partial, u_true):\n",
    "        o, u = self.forward(x_partial)\n",
    "        return self.L2loss(u, u_true)\n",
    "    \n",
    "    def join_partial_future_signal(self, x_partial, x_future):\n",
    "        return torch.cat([x_partial, x_future], 0)\n",
    "    \n",
    "    def STL_loss_n(self, n, x_partial, formula, formula_input_func, dynamics, **kwargs):\n",
    "\n",
    "        x_future = self.propagate_n(n, x_partial, dynamics)\n",
    "        x_complete = self.join_partial_future_signal(x_partial, x_future)\n",
    "        return torch.relu(-formula.robustness(formula_input_func(x_complete), **kwargs)).mean()\n",
    "    \n",
    "    def STL_loss(self, x, formula, formula_input_func, **kwargs):\n",
    "        return torch.relu(-formula.robustness(formula_input_func(x), **kwargs)).mean()\n",
    "    \n",
    "#     def \n",
    "#     def HJI_loss(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwe = \"popo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = HJIValueFunction().apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popo\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "HJIValueFunctionBackward.forward: expected Variable (got int) for return value 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-294-2a68758f5284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: HJIValueFunctionBackward.forward: expected Variable (got int) for return value 0"
     ]
    }
   ],
   "source": [
    "vf(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = np.array([[0, 1, 1, 0],[0, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.3\n",
    "y0 = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp1D(x0, xs, vs):\n",
    "    gamma = (x0 - xs[:,:1])/(xs[:,1:] - xs[:,:1])\n",
    "    return (1 - gamma) * vs[:,:1] + gamma * vs[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.3 * torch.ones([10, 1])\n",
    "xs = torch.zeros([10, 2])\n",
    "xs[:,1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000],\n",
       "        [0.3000]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interp1D(x0, xys, vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of corners [bl, br, tr tl]\n",
    "# xy0 [bs, 2]\n",
    "# xys [bs, 4, 2]\n",
    "# vs [bs, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "xy0 = torch.zeros([bs, 2])\n",
    "xy0[:,0] = 0.3\n",
    "xy0[:,1] = 0.7\n",
    "xys = torch.cat([torch.tensor([0, 1, 1, 0]).float().unsqueeze(0).unsqueeze(-1).repeat([bs, 1, 1]), torch.tensor([0, 0, 1, 1]).float().unsqueeze(0).unsqueeze(-1).repeat([bs, 1, 1])], dim=-1)\n",
    "vs = torch.zeros([bs, 4])\n",
    "vs[:,1] = 1\n",
    "vs[:,2] = 2\n",
    "vs[:,3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = (xy0 - xys[:,0,:]) / (xys[:,2,:] - xys[:,0,:])    # [bs, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000],\n",
       "        [0.7000, 0.3000]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2999999999999998"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interp2D(xy0, xys, vs):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V(corners[0,:], corners[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3.7 (ctrl_syn)",
   "language": "python",
   "name": "ctrl_syn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
